{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method to determine the similarity string kernel for n-grams\n",
    "def ngram_similarity(s1, s2, n = 4):\n",
    "    nr = 0  # number of n-grams in common\n",
    "\n",
    "    for i in range(len(s1)-n+1):\n",
    "        ngram = s1[i:i+n]\n",
    "        if ngram in s2:\n",
    "            nr += 1\n",
    "\n",
    "    return nr\n",
    "\n",
    "# call the method to determine the similarity string kernel for n-grams\n",
    "ngram_similarity('ananas copt', 'banana verde', 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "0.895\n",
      "0.905\n",
      "0.905\n",
      "0.89\n",
      "0.895\n",
      "0.89\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Define the training data as a list of text documents\n",
    "train_data = np.load ('train_data.npy')\n",
    "train_labels = np.load ('train_labels.npy')\n",
    "\n",
    "# transform the data into numpy arrays\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "\n",
    "train_mock_data = train_data [:800]\n",
    "train_mock_labels = train_labels [:800]\n",
    "\n",
    "\n",
    "validation_mock_data = train_data [800:]\n",
    "validation_mock_labels = train_labels [800:]\n",
    "\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__ (self, train_data, train_labels, k):\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "        self.k = k\n",
    "\n",
    "    def predict_data (self, test_data):\n",
    "       \n",
    "       distances = [ngram_similarity(train_d, test_data, 8) for train_d in self.train_data]\n",
    "       sorted_distances = np.argsort(distances)[::-1]\n",
    "       nearest_index = sorted_distances[:self.k]\n",
    "       k_nearest_labels = self.train_labels [nearest_index]\n",
    "\n",
    "\n",
    "       return np.sign(np.sum(k_nearest_labels))\n",
    "    \n",
    "\n",
    "    def classify_data (self, test_data):\n",
    "       predicted_labels = np.zeros(len(test_data))\n",
    "       for i in range(len(test_data)):\n",
    "              predicted_labels[i] = self.predict_data(test_data[i])\n",
    "\n",
    "       return predicted_labels\n",
    "\n",
    "\n",
    "    def accuracy (self, test_labels, predicted_labels):\n",
    "        return np.mean(test_labels == predicted_labels)  \n",
    "\n",
    "\n",
    "for k in [1, 3, 5, 7, 9, 11, 13, 15]: \n",
    "    \n",
    "    knn = KNNClassifier(train_mock_data, train_mock_labels, k)\n",
    "\n",
    "    predicted_labels = knn.classify_data(validation_mock_data)\n",
    "\n",
    "    accuracy = knn.accuracy(validation_mock_labels, predicted_labels)\n",
    "\n",
    "    print(accuracy)\n",
    "\n",
    "# maximul e k = 5\n",
    "\n",
    "# test data and print in a file the predicted labels\n",
    "# test_data = np.load ('test_data.npy')\n",
    "# test_data = np.array(test_data)\n",
    "\n",
    "# with open('test_labels.txt', 'w') as f:\n",
    "#     for i in range(len(test_data)):\n",
    "#         f.write(str(knn.predict_data(test_data[i])) + '\\n')\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136.   7.   0. ...   0.   0.   0.]\n",
      " [  7. 172.   0. ...  10.   0.   6.]\n",
      " [  0.   0.  47. ...   0.   0.   4.]\n",
      " ...\n",
      " [  0.   4.   0. ... 107.   0.   2.]\n",
      " [  0.   0.   0. ...   0. 164.   0.]\n",
      " [  0.   2.   4. ...   2.   0.  92.]]\n",
      "[[ 0.  1.  0. ...  0.  0.  2.]\n",
      " [ 0.  1.  0. ...  1.  0.  3.]\n",
      " [ 0.  0.  0. ...  1.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 9. 10. 14. ...  4.  0. 16.]\n",
      " [ 0.  0.  5. ...  1.  3.  9.]]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.load ('test_data.npy')\n",
    "\n",
    "def kernel_matrix_train(train_mock_data, n):\n",
    "    # initialize the kernel matrix\n",
    "    kernel = np.zeros((len(train_mock_data), len(train_mock_data)))\n",
    "\n",
    "    # compute the similarity for each pair of strings\n",
    "    for i in range(len(train_mock_data)):\n",
    "        for j in range(len(train_mock_data)):\n",
    "            kernel[i][j] = ngram_similarity(train_mock_data[i], train_mock_data[j], n)\n",
    "    return kernel\n",
    "\n",
    "kernel_train = kernel_matrix_train(train_mock_data, 8)\n",
    "print (kernel_train)\n",
    "\n",
    "# create kernel matrix for the train set and test set\n",
    "def kernel_matrix_test(validation_mock_data,train_mock_data,  n):\n",
    "    # initialize the kernel matrix\n",
    "    kernel = np.zeros((len(validation_mock_data),len(train_mock_data)))\n",
    "\n",
    "    # compute the similarity for each pair of strings\n",
    "    for i in range(len(validation_mock_data)):\n",
    "        for j in range(len(train_mock_data)):\n",
    "            kernel[i][j] = ngram_similarity(validation_mock_data[i], train_mock_data[j], n)\n",
    "    return kernel\n",
    "\n",
    "# compute the kernel matrix for the train set and data set\n",
    "kernel_test = kernel_matrix_test(validation_mock_data, train_mock_data, 8)\n",
    "print (kernel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valoarea de predicti pt alpha = 0.1 este 0.93\n",
      "valoarea de predicti pt alpha = 1 este 0.93\n",
      "valoarea de predicti pt alpha = 10 este 0.94\n",
      "valoarea de predicti pt alpha = 100 este 0.95\n",
      "valoarea de predicti pt alpha = 1000 este 0.91\n"
     ]
    }
   ],
   "source": [
    "# train krr model with kernel precomputed\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# initialize the model\n",
    "for alfa_val in [0.1, 1, 10, 100, 1000]:\n",
    "\n",
    "    krr_model = KernelRidge(alpha=alfa_val, kernel='precomputed')\n",
    "    \n",
    "    krr_model.fit(kernel_train, train_mock_labels)\n",
    "\n",
    "    # predict the labels for the test set\n",
    "    predicted_labels = krr_model.predict(kernel_test)\n",
    "\n",
    "    predictii = []\n",
    "\n",
    "    for label in predicted_labels:\n",
    "        if label <= 0 :\n",
    "            predictii.append(-1)\n",
    "        else :\n",
    "            predictii.append(1)\n",
    "\n",
    "    print(f\"valoarea de predicti pt alpha = {alfa_val} este {(np.array(predictii) == validation_mock_labels).mean()}\")\n",
    "\n",
    "    # determine the accuracy of the model\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
